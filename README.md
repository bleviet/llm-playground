# LLM Playground - Professional Architecture for LLM Applications

A **learning-focused workspace** demonstrating professional software architecture patterns for building LLM applications.

## ğŸ¯ Repository Vision

This repository teaches you how to:
- âœ… Build **reusable** LLM provider infrastructure
- âœ… Apply **design patterns** (Strategy, Provider, Dependency Injection)
- âœ… Follow **SOLID principles** in real projects
- âœ… Structure **multi-application** workspaces
- âœ… Write **production-ready** code

## ğŸ“ Repository Structure

```
llm-playground/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md    # GitHub Copilot guidance
â”œâ”€â”€ AGENTS.md                       # AI agent instructions
â”œâ”€â”€ .editorconfig                   # Editor settings
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ llm_core/                       # ğŸ”§ Shared LLM provider infrastructure
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ providers/                  # Provider implementations
â”‚   â”‚   â”œâ”€â”€ base_provider.py
â”‚   â”‚   â”œâ”€â”€ ollama.py
â”‚   â”‚   â”œâ”€â”€ openai.py
â”‚   â”‚   â”œâ”€â”€ gemini.py
â”‚   â”‚   â””â”€â”€ strategies/             # API communication strategies
â”‚   â”‚       â”œâ”€â”€ base_strategy.py
â”‚   â”‚       â”œâ”€â”€ openai_api_strategy.py
â”‚   â”‚       â””â”€â”€ gemini_native_strategy.py
â”‚   â””â”€â”€ utils/                      # Shared utilities
â”‚
â””â”€â”€ applications/                   # ğŸ“± Applications using llm_core
    â””â”€â”€ summarize_webpage/          # Web summarization app
        â”œâ”€â”€ README.md
        â”œâ”€â”€ ARCHITECTURE.md
        â”œâ”€â”€ QUICKSTART.md
        â”œâ”€â”€ DEPENDENCIES.md
        â”œâ”€â”€ pyproject.toml
        â”œâ”€â”€ requirements.txt
        â”œâ”€â”€ .env.example
        â”œâ”€â”€ scraper.py
        â”œâ”€â”€ summarize_webpage.py
        â””â”€â”€ core/
            â””â”€â”€ summarizer.py
```

## ğŸ”§ LLM Core (Shared Infrastructure)

**Purpose**: Reusable provider pattern for multiple LLM services

**Features**:
- Abstract provider interface
- Strategy pattern for different APIs
- Support for Ollama, OpenAI, Gemini
- Easy to extend with new providers

**Usage**:
```python
from llm_core.providers.openai import OpenAIProvider

provider = OpenAIProvider(model_name="gpt-4o-mini")
client = provider.get_client()
response = provider.summarize(client, content, system_prompt, user_prompt)
```

See [`llm_core/README.md`](llm_core/README.md) for details.

## ğŸ“± Applications

### 1. Summarize Webpage

**What it does**: Fetches web content and generates summaries using multiple LLM providers

**Key features**:
- JavaScript-enabled web scraping (Playwright)
- Side-by-side provider comparison
- Beautiful terminal output (Rich)

**Quick start**:
```bash
# 1. Install llm_core
cd llm_core
pip install -e .

# 2. Install application
cd ../applications/summarize_webpage
pip install -r requirements.txt
python -m playwright install

# 3. Configure API keys
cp .env.example .env
# Edit .env with your API keys

# 4. Run
python summarize_webpage.py
```

See [`applications/summarize_webpage/README.md`](applications/summarize_webpage/README.md) for details.

## ğŸš€ Getting Started

### 1. Install llm_core (required)

```bash
cd llm_core
pip install -e .
```

Or with uv:
```bash
cd llm_core
uv pip install -e .
```

The `-e` flag installs in "editable" mode, so changes to `llm_core` are immediately available.

### 2. Choose an application

```bash
cd applications/summarize_webpage
pip install -r requirements.txt
python -m playwright install
```

### 3. Configure API keys

Create `.env` in the application directory:
```bash
cp .env.example .env
```

Edit `.env` and add your keys:
```env
OPENAI_API_KEY=your-key-here
GEMINI_API_KEY=your-key-here
```

### 4. Run

```bash
python summarize_webpage.py
```

## ğŸ“ Learning Path

### Beginner
1. Run `summarize_webpage` and observe output
2. Read [`llm_core/README.md`](llm_core/README.md) to understand providers
3. Modify prompts in `applications/summarize_webpage/core/summarizer.py`
4. Try different models by editing `summarize_webpage.py`

### Intermediate
1. Add a new provider (e.g., Anthropic Claude) to `llm_core`
2. Create a new application using `llm_core`
3. Read [`applications/summarize_webpage/ARCHITECTURE.md`](applications/summarize_webpage/ARCHITECTURE.md)
4. Implement error handling improvements

### Advanced
1. Add streaming support to providers
2. Implement async parallel processing
3. Build a web API wrapper with FastAPI
4. Add comprehensive test suite
5. Create a new strategy for a different API type

## ğŸ“š Documentation

- [`AGENTS.md`](AGENTS.md) - AI agent instructions for this repo
- [`.github/copilot-instructions.md`](.github/copilot-instructions.md) - GitHub Copilot guidance
- [`llm_core/README.md`](llm_core/README.md) - Provider infrastructure docs
- [`applications/summarize_webpage/ARCHITECTURE.md`](applications/summarize_webpage/ARCHITECTURE.md) - Design patterns explained
- [`applications/summarize_webpage/QUICKSTART.md`](applications/summarize_webpage/QUICKSTART.md) - 30-minute tutorial

## ğŸ—ï¸ Architecture Philosophy

### Separation of Concerns

```
llm_core/          â†’ "How do I talk to LLMs?"
applications/      â†’ "What do I do with LLMs?"
```

**Benefits**:
- Providers can be reused across multiple applications
- Changes to providers don't affect applications
- Easy to test each layer independently
- Clear boundaries and responsibilities

### Design Patterns

- **Strategy Pattern**: Pluggable API communication strategies
  - `OpenAIAPIStrategy` - Works with OpenAI-compatible APIs
  - `GeminiNativeStrategy` - Uses Google's native SDK
  - Easy to add new strategies without modifying providers

- **Provider Pattern**: Unified interface for multiple LLM services
  - `BaseProvider` - Abstract interface
  - `OllamaProvider`, `OpenAIProvider`, `GeminiProvider` - Concrete implementations
  - All providers have the same interface

- **Dependency Injection**: Flexible, testable components
  - Strategies are injected into providers
  - Providers are injected into applications
  - Easy to mock for testing

### SOLID Principles

Every module follows:
- **S**ingle Responsibility - Each class has one reason to change
- **O**pen/Closed - Open for extension, closed for modification
- **L**iskov Substitution - Providers are interchangeable
- **I**nterface Segregation - Focused interfaces
- **D**ependency Inversion - Depend on abstractions, not concretions

## ğŸ› ï¸ Future Applications

Ideas for new applications using `llm_core`:

1. **Document Q&A** - Ask questions about PDFs/docs
2. **Code Explainer** - Analyze and explain code
3. **Sentiment Analyzer** - Analyze text sentiment
4. **Translation Tool** - Multi-provider translation
5. **Meeting Summarizer** - Summarize transcripts
6. **Email Composer** - Draft emails with different tones
7. **Content Generator** - Generate blog posts, social media
8. **Data Analyst** - Natural language data queries

Each application:
- Uses `llm_core` providers
- Has its own dependencies
- Follows the same architectural patterns
- Lives in `applications/` directory

## ğŸ¤ Contributing

This is a learning project! Contributions welcome:
- Add new providers to `llm_core`
- Build new applications
- Improve documentation
- Add tests
- Fix bugs

See [`.github/copilot-instructions.md`](.github/copilot-instructions.md) for coding guidelines.

## ğŸ“„ License

MIT License - Free for learning and commercial use

---

## ğŸ” Why This Structure?

### Before: Monolithic
```
summarize_webpage/
â”œâ”€â”€ providers/         # Locked inside one app
â””â”€â”€ app logic
```

**Problems**:
- Can't reuse providers
- Duplicates code for new apps
- Hard to maintain

### After: Modular
```
llm_core/              # Reusable infrastructure
applications/          # Multiple apps sharing llm_core
```

**Benefits**:
- âœ… Reuse providers everywhere
- âœ… Add apps easily
- âœ… Test independently
- âœ… Professional structure

---

**Happy Learning!** ğŸš€

*Remember: We're not just writing code that worksâ€”we're writing code that teaches.*
